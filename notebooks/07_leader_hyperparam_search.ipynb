{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define project directories\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "DATA_RAW = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "SPLITS_DIR = PROJECT_ROOT / \"data\" / \"splits\"\n",
    "REPORTS_DIR = PROJECT_ROOT / \"reports\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "DATA_RAW.mkdir(parents=True, exist_ok=True)\n",
    "SPLITS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_RAW / \"house_prices_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COL = \"SalePrice\"\n",
    "\n",
    "# Separate features and target variable\n",
    "y = df[TARGET_COL]\n",
    "X = df.drop(columns=[TARGET_COL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = np.load(SPLITS_DIR / \"train_indices.npy\")\n",
    "test_idx = np.load(SPLITS_DIR / \"test_indices.npy\")\n",
    "\n",
    "X_train = X.loc[train_idx].copy()\n",
    "y_train = y.loc[train_idx].copy()\n",
    "\n",
    "X_test = X.loc[test_idx].copy()\n",
    "y_test = y.loc[test_idx].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']\n",
      "Numeric columns: ['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']\n"
     ]
    }
   ],
   "source": [
    "# Identify numeric and categorical columns\n",
    "numeric_cols = X_train.select_dtypes(include=[\"int64\", \"float64\"]).columns.to_list()\n",
    "if 'Id' in numeric_cols:\n",
    "    numeric_cols.remove('Id')\n",
    "categorical_cols = X_train.select_dtypes(include=[\"object\", \"category\"]).columns.to_list()\n",
    "\n",
    "print(f\"Categorical columns: {categorical_cols}\")\n",
    "print(f\"Numeric columns: {numeric_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing pipelines for numeric and categorical data\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)), \n",
    "    ]\n",
    ")\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_cols),\n",
    "        (\"cat\", categorical_transformer, categorical_cols),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'regressor__regressor__learning_rate': np.float64(0.1254335218612733), 'regressor__regressor__max_iter': 120, 'regressor__regressor__max_leaf_nodes': 23, 'regressor__regressor__min_samples_leaf': 11}\n",
      "Best Score: -27743.102384165988\n"
     ]
    }
   ],
   "source": [
    "hgb_model = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"regressor\", HistGradientBoostingRegressor(\n",
    "            max_iter=100,  \n",
    "            learning_rate=0.1, \n",
    "            max_depth=None,  \n",
    "            random_state=RANDOM_STATE,\n",
    "            min_samples_leaf=20, \n",
    "            max_leaf_nodes=31, \n",
    "            early_stopping=True,  \n",
    "            validation_fraction=0.1, \n",
    "        )),\n",
    "    ]\n",
    ")\n",
    "\n",
    "log_target_model = TransformedTargetRegressor(\n",
    "    regressor=hgb_model,\n",
    "    func=np.log1p,   \n",
    "    inverse_func=np.expm1,  \n",
    ")\n",
    "\n",
    "param_distributions = {\n",
    "    \"regressor__regressor__learning_rate\": uniform(0.01, 0.19),  \n",
    "    \"regressor__regressor__max_leaf_nodes\": randint(15, 50),     \n",
    "    \"regressor__regressor__min_samples_leaf\": randint(5, 30),    \n",
    "    \"regressor__regressor__max_iter\": randint(100, 600),        \n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=log_target_model, \n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=40,\n",
    "    scoring={\n",
    "        \"neg_root_mean_squared_error\": \"neg_root_mean_squared_error\",\n",
    "        \"neg_mean_absolute_error\": \"neg_mean_absolute_error\",\n",
    "    },\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    refit=\"neg_root_mean_squared_error\",\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = random_search.best_params_\n",
    "best_score = -random_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "P2 House Prices",
   "language": "python",
   "name": "p2-house-prices"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
